{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter notebook file to test model, without having to rerun everything"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.viewer import ImageViewer\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import feature\n",
    "from skimage.filters import gaussian\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import random\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Activation, RandomCrop, RandomFlip, RandomTranslation, RandomRotation, RandomZoom, RandomContrast, RandomBrightness\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emmar\\AppData\\Local\\Temp\\ipykernel_18960\\2925268095.py:10: FutureWarning: `multichannel` is a deprecated argument name for `gaussian`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
      "  gaussian_filter = gaussian(image, multichannel=True, sigma=2)\n"
     ]
    }
   ],
   "source": [
    "#load test image\n",
    "image = imread(\"C:/Users/emmar/Documents/GitHub/VISN/Opdracht_1/flower.jpg\")\n",
    "\n",
    "#grayscale\n",
    "image_gray = rgb2gray(image)\n",
    "\n",
    "#edge detection\n",
    "canny_filter = feature.canny(image_gray, sigma=2) \n",
    "\n",
    "#gaussian filter                    #for rgb image\n",
    "gaussian_filter = gaussian(image, multichannel=True, sigma=2) \n",
    "\n",
    "# viewer = ImageViewer(image)\n",
    "# viewer.show()\n",
    "\n",
    "# viewer = ImageViewer(image_gray)\n",
    "# viewer.show()\n",
    "\n",
    "# viewer = ImageViewer(canny_filter)\n",
    "# viewer.show()\n",
    "\n",
    "# viewer = ImageViewer(gaussian_filter)\n",
    "# viewer.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in the dataset\n",
    "Dataset used for this project from: https://www.kaggle.com/datasets/grassknoted/asl-alphabet?resource=download\n",
    "Tutorial: https://www.youtube.com/watch?v=j-3vuBynnOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "B\n",
      "C\n",
      "D\n",
      "E\n",
      "F\n",
      "G\n",
      "H\n",
      "I\n",
      "J\n",
      "K\n",
      "L\n",
      "M\n",
      "N\n",
      "O\n",
      "P\n",
      "Q\n",
      "R\n",
      "S\n",
      "T\n",
      "U\n",
      "V\n",
      "W\n",
      "X\n",
      "Y\n",
      "Z\n",
      "del\n",
      "nothing\n",
      "space\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = \"C:/Users/emmar/Documents/GitHub/VISN/Eindopdracht/dataset/asl_alphabet_train/asl_alphabet_train\"\n",
    "letters = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n",
    "\n",
    "training_data = []\n",
    "\n",
    "for letter in letters:\n",
    "    #get directory of a certain letter\n",
    "    path = os.path.join(dataset_dir, letter)\n",
    "\n",
    "    #create number for each letter\n",
    "    letter_num = letters.index(letter)\n",
    "    print(letter)\n",
    "    \n",
    "    for image in os.listdir(path):\n",
    "        #get one image\n",
    "        image_array = cv2.imread(os.path.join(path, image), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        #compress the image to a smaller resolution\n",
    "        image_size = 50\n",
    "        compressed_image_array = cv2.resize(image_array, (image_size, image_size))\n",
    "\n",
    "        #add canny filter\n",
    "        # canny_filter_image = feature.canny(compressed_image_array, sigma=3)\n",
    "\n",
    "        #add gaussian filter\n",
    "        # gaussian_filter_image = gaussian(compressed_image_array, sigma=2)\n",
    "\n",
    "        #add new image to the training set\n",
    "        training_data.append([compressed_image_array, letter_num])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formating the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#randomize the images\n",
    "random.shuffle(training_data)\n",
    "\n",
    "plt.imshow(training_data[0][0])\n",
    "\n",
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "test_data_size = 10000\n",
    "\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "#separate images and labels into the testing dataset\n",
    "#(the first 10.000) and the training dataset (the rest)\n",
    "\n",
    "#TODO can this be done easier? split?\n",
    "for i in range(len(training_data)):\n",
    "    if i < test_data_size:\n",
    "        test_images.append(training_data[i][0])\n",
    "        test_labels.append(training_data[i][1])\n",
    "    else:\n",
    "        train_images.append(training_data[i][0])\n",
    "        train_labels.append(training_data[i][1])\n",
    "\n",
    "#reshape train and test images\n",
    "train_images = np.array(train_images).reshape(-1, image_size, image_size, 1)\n",
    "test_images = np.array(test_images).reshape(-1, image_size, image_size, 1)\n",
    "\n",
    "#normalize the images\n",
    "train_images = (train_images / 255) - 0.5\n",
    "test_images = (test_images / 255) - 0.5\n",
    "\n",
    "#normalize the images canny\n",
    "# train_images = train_images - 0.5\n",
    "# test_images = test_images - 0.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and testing the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2046/2046 [==============================] - 110s 52ms/step - loss: 1.4121 - accuracy: 0.5914 - val_loss: 7.3418 - val_accuracy: 0.3454\n",
      "Epoch 2/20\n",
      "2046/2046 [==============================] - 111s 54ms/step - loss: 0.5041 - accuracy: 0.8467 - val_loss: 9.2069 - val_accuracy: 0.3860\n",
      "Epoch 3/20\n",
      "2046/2046 [==============================] - 108s 53ms/step - loss: 0.3297 - accuracy: 0.8987 - val_loss: 10.4730 - val_accuracy: 0.3906\n",
      "Epoch 4/20\n",
      "2046/2046 [==============================] - 103s 50ms/step - loss: 0.2521 - accuracy: 0.9214 - val_loss: 10.6197 - val_accuracy: 0.4281\n",
      "Epoch 5/20\n",
      "2046/2046 [==============================] - 106s 52ms/step - loss: 0.2011 - accuracy: 0.9387 - val_loss: 12.7482 - val_accuracy: 0.4051\n",
      "Epoch 6/20\n",
      "2046/2046 [==============================] - 104s 51ms/step - loss: 0.1720 - accuracy: 0.9472 - val_loss: 12.8432 - val_accuracy: 0.4227\n",
      "Epoch 7/20\n",
      "2046/2046 [==============================] - 103s 50ms/step - loss: 0.1471 - accuracy: 0.9549 - val_loss: 13.4327 - val_accuracy: 0.4328\n",
      "Epoch 8/20\n",
      "2046/2046 [==============================] - 103s 50ms/step - loss: 0.1254 - accuracy: 0.9617 - val_loss: 12.8294 - val_accuracy: 0.4584\n",
      "Epoch 9/20\n",
      "2046/2046 [==============================] - 108s 53ms/step - loss: 0.1123 - accuracy: 0.9658 - val_loss: 14.0288 - val_accuracy: 0.4565\n",
      "Epoch 10/20\n",
      "2046/2046 [==============================] - 104s 51ms/step - loss: 0.1054 - accuracy: 0.9683 - val_loss: 12.4561 - val_accuracy: 0.4718\n",
      "Epoch 11/20\n",
      "2046/2046 [==============================] - 109s 53ms/step - loss: 0.0852 - accuracy: 0.9743 - val_loss: 12.7679 - val_accuracy: 0.4886\n",
      "Epoch 12/20\n",
      "2046/2046 [==============================] - 107s 53ms/step - loss: 0.0851 - accuracy: 0.9743 - val_loss: 14.1375 - val_accuracy: 0.4638\n",
      "Epoch 13/20\n",
      "2046/2046 [==============================] - 110s 54ms/step - loss: 0.0759 - accuracy: 0.9779 - val_loss: 16.7215 - val_accuracy: 0.4490\n",
      "Epoch 14/20\n",
      "2046/2046 [==============================] - 110s 54ms/step - loss: 0.0716 - accuracy: 0.9781 - val_loss: 15.2282 - val_accuracy: 0.4667\n",
      "Epoch 15/20\n",
      "2046/2046 [==============================] - 111s 54ms/step - loss: 0.0649 - accuracy: 0.9811 - val_loss: 13.9529 - val_accuracy: 0.4863\n",
      "Epoch 16/20\n",
      "2046/2046 [==============================] - 113s 55ms/step - loss: 0.0670 - accuracy: 0.9803 - val_loss: 13.4846 - val_accuracy: 0.4849\n",
      "Epoch 17/20\n",
      "2046/2046 [==============================] - 109s 53ms/step - loss: 0.0532 - accuracy: 0.9843 - val_loss: 14.3203 - val_accuracy: 0.4958\n",
      "Epoch 18/20\n",
      "2046/2046 [==============================] - 105s 51ms/step - loss: 0.0566 - accuracy: 0.9829 - val_loss: 15.4290 - val_accuracy: 0.4906\n",
      "Epoch 19/20\n",
      "2046/2046 [==============================] - 111s 54ms/step - loss: 0.0479 - accuracy: 0.9859 - val_loss: 16.4972 - val_accuracy: 0.4726\n",
      "Epoch 20/20\n",
      "2046/2046 [==============================] - 121s 59ms/step - loss: 0.0499 - accuracy: 0.9854 - val_loss: 15.4557 - val_accuracy: 0.4888\n",
      "313/313 - 4s - loss: 15.2958 - accuracy: 0.4774 - 4s/epoch - 12ms/step\n",
      "0.477400004863739\n"
     ]
    }
   ],
   "source": [
    "#setting the model variables\n",
    "num_filters = 30\n",
    "filter_size = 3\n",
    "pool_size = 2\n",
    "num_epochs = 20\n",
    "\n",
    "#creating the model and adding the layers\n",
    "model = Sequential([\n",
    "\n",
    "    RandomContrast(0.2),\n",
    "    RandomBrightness(0.2, value_range=(-0.5, 0.5)),\n",
    "\n",
    "    Conv2D(num_filters, filter_size, input_shape=train_images[0].shape),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "\n",
    "    Conv2D(num_filters, filter_size, activation='relu'),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(29, activation=\"sigmoid\", name=\"dense\")\n",
    "])\n",
    "\n",
    "model.compile('adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#training the model\n",
    "model.fit(train_images, to_categorical(train_labels), epochs=num_epochs, validation_split=0.15)\n",
    "\n",
    "#testing the model\n",
    "test_loss, test_acc = model.evaluate(test_images,  to_categorical(test_labels), verbose=2)\n",
    "print(test_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "A\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "B\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "C\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "D\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "E\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "F\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "P\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "H\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "D\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "P\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "K\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "L\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "M\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "N\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "O\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "P\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "L\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "L\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "L\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "U\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "W\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "W\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "L\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Y\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Z\n"
     ]
    }
   ],
   "source": [
    "#for each letter\n",
    "for i in range(len(letters) - 3):\n",
    "    #open the test image version of the letter\n",
    "    path = \"C:/Users/emmar/Documents/GitHub/VISN/Eindopdracht/dataset/asl_alphabet_test/asl_alphabet_test/\"+letters[i]+\"_test.jpg\"\n",
    "    image_to_predict = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    #preprocess the image the same as images used for training\n",
    "    compressed_image_to_predict = cv2.resize(image_to_predict, (image_size, image_size))\n",
    "    reshaped_image_to_predict = compressed_image_to_predict.reshape(-1, image_size, image_size, 1)\n",
    "    normalized_image_to_predict = (reshaped_image_to_predict / 255) - 0.5\n",
    "\n",
    "    #predict the letter\n",
    "    prediction = model.predict(normalized_image_to_predict)\n",
    "\n",
    "    #print the actual letter instead of percentages\n",
    "    predicted_letter = list(prediction[0]).index(max(prediction[0]))\n",
    "    # print(prediction)\n",
    "    print(letters[predicted_letter])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the model with the captured dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "A\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "W\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "D\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "F\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "D\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "F\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "G\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Y\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "W\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "G\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "W\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "D\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "W\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "W\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "D\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "D\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "G\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "W\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "B\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "D\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "W\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "W\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "W\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "W\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "F\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "F\n"
     ]
    }
   ],
   "source": [
    "#for each letter\n",
    "for i in range(len(letters) - 3):\n",
    "    #open the test capture image version of the letter\n",
    "    path = \"C:/Users/emmar/Documents/GitHub/VISN/Eindopdracht/dataset/asl_alphabet_test/als_alphabet_test_captures/\"+letters[i]+\"_test.jpg\"\n",
    "    image_to_predict = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    #preprocess the image the same as images used for training\n",
    "    compressed_image_to_predict = cv2.resize(image_to_predict, (image_size, image_size))\n",
    "    reshaped_image_to_predict = compressed_image_to_predict.reshape(-1, image_size, image_size, 1)\n",
    "    normalized_image_to_predict = (reshaped_image_to_predict / 255) - 0.5\n",
    "\n",
    "    #predict the letter\n",
    "    prediction = model.predict(normalized_image_to_predict)\n",
    "\n",
    "    #print the actual letter instead of percentages\n",
    "    predicted_letter = list(prediction[0]).index(max(prediction[0]))\n",
    "    # print(prediction)\n",
    "    print(letters[predicted_letter])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"ASL_model.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
