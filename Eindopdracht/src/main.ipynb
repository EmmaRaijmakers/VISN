{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emmar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\skimage\\viewer\\utils\\__init__.py:1: UserWarning: Recommended matplotlib backend is `Agg` for full skimage.viewer functionality.\n",
      "  from .core import *\n"
     ]
    }
   ],
   "source": [
    "from skimage.viewer import ImageViewer\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import feature\n",
    "from skimage.filters import gaussian\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import random\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imread(\"Opdracht_1/flower.jpg\")\n",
    "\n",
    "#grayscale\n",
    "image_gray = rgb2gray(image)\n",
    "\n",
    "#edge detection\n",
    "canny_filter = feature.canny(image_gray, sigma=2.1) #TODO change sigma\n",
    "\n",
    "#gaussian filter                    #for rgb image\n",
    "gaussian_filter = gaussian(image, multichannel=True, sigma=2) #TODO change sigma\n",
    "\n",
    "# viewer = ImageViewer(image)\n",
    "# viewer.show()\n",
    "\n",
    "# viewer = ImageViewer(image_gray)\n",
    "# viewer.show()\n",
    "\n",
    "# viewer = ImageViewer(canny_filter)\n",
    "# viewer.show()\n",
    "\n",
    "# viewer = ImageViewer(gaussian_filter)\n",
    "# viewer.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in the dataset\n",
    "Dataset used for this project from: https://www.kaggle.com/datasets/grassknoted/asl-alphabet?resource=download\n",
    "Tutorial: https://www.youtube.com/watch?v=j-3vuBynnOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"Eindopdracht/dataset/asl_alphabet_train/asl_alphabet_train\"\n",
    "letters = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n",
    "\n",
    "training_data = []\n",
    "\n",
    "for letter in letters:\n",
    "    #get directory of a certain letter\n",
    "    path = os.path.join(dataset_dir, letter)\n",
    "\n",
    "    #create number for each letter\n",
    "    letter_num = letters.index(letter)\n",
    "    print(letter)\n",
    "    \n",
    "    for image in os.listdir(path):\n",
    "        #get one image\n",
    "        image_array = cv2.imread(os.path.join(path, image), cv2.IMREAD_GRAYSCALE) #TODO gray scale can be added here, do it??\n",
    "\n",
    "        #compress the image to a smaller resolution\n",
    "        #TODO is this needed?? > makes faster\n",
    "        image_size = 50 #TODO this bigger/smaller?\n",
    "        compressed_image_array = cv2.resize(image_array, (image_size, image_size))\n",
    "\n",
    "        #add new image to the training set\n",
    "        training_data.append([compressed_image_array, letter_num])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formating the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomize the images\n",
    "random.shuffle(training_data)\n",
    "\n",
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "test_data_size = 10000\n",
    "\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "#separate images and labels into the testing dataset\n",
    "#(the first 10.000) and the training dataset (the rest)\n",
    "\n",
    "#TODO can this be done easier? split?\n",
    "for i in range(len(training_data)):\n",
    "    if i < test_data_size:\n",
    "        test_images.append(training_data[i][0])\n",
    "        test_labels.append(training_data[i][1])\n",
    "    else:\n",
    "        train_images.append(training_data[i][0])\n",
    "        train_labels.append(training_data[i][1])\n",
    "\n",
    "#reshape train and test images\n",
    "train_images = np.array(train_images).reshape(-1, image_size, image_size, 1)\n",
    "test_images = np.array(test_images).reshape(-1, image_size, image_size, 1)\n",
    "\n",
    "#normalize the images\n",
    "train_images = (train_images / 255) - 0.5\n",
    "test_images = (test_images / 255) - 0.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and testing the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10 #TODO change this var\n",
    "\n",
    "model = Sequential([\n",
    "    #TODO add layers\n",
    "])\n",
    "\n",
    "model.compile('adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, to_categorical(train_labels), epochs=num_epochs, validation_data=(test_images, to_categorical(test_labels)))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  to_categorical(test_labels), verbose=2)\n",
    "print(test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
